{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import & Ingest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "SOURCE_PATH = pathlib.Path.cwd().resolve().parent\n",
    "sys.path.append(str(SOURCE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from utils import *\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, classification_report, make_scorer, f1_score\n",
    "from sklearn.utils import class_weight\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DATA_PATH.joinpath(\"match_predict.csv\")\n",
    "df = pd.read_csv(data)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To begin, I test linear and Random Forest regression on predicting the home score advantage (home goals minus away goals)\n",
    "#to probe the viability of precise prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-hot encoding the categorical columns\n",
    "cat_cols = ['Country',\n",
    " 'League',\n",
    " 'home_buildUpPlayPositioningClass',\n",
    " 'home_chanceCreationPositioningClass',\n",
    " 'home_defenceDefenderLineClass',\n",
    " 'away_buildUpPlayPositioningClass',\n",
    " 'away_chanceCreationPositioningClass',\n",
    " 'away_defenceDefenderLineClass']\n",
    "\n",
    "df[cat_cols].nunique() #I will drop_first for the binary columns but not the ones with more than two categories.\n",
    "#For linear regression, this allows all the columns to be used.\n",
    "#For ensemble methods, if a feature has more than one category, then the dropped level could implicitly become important to a tree split,\n",
    "#and therefore keeping it would afford greater explicit interpretability after the fact. (This isn't an issue with binary columns, because\n",
    "#keeping the second column is just redundant.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_cat_cols = ['Country',\n",
    "'League']\n",
    "\n",
    "binary_cat_cols = [col for col in df.columns if \"class\" in col.lower()]\n",
    "\n",
    "def one_hot_encode(df):\n",
    "    df_multi = pd.get_dummies(df[multi_cat_cols], drop_first = False).astype(int)\n",
    "    df_binary = pd.get_dummies(df[binary_cat_cols], drop_first = True).astype(int)\n",
    "    df_num = df.drop(columns = cat_cols)\n",
    "    df = pd.concat([df_num, df_binary, df_multi], axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = one_hot_encode(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns = [\"Home_Score_Adv\"]), df.Home_Score_Adv\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No shuffling--maintaining temporal integrity and predicting future matches, as the model would do if realistically deployed.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_train_pred = lr.predict(X_train)\n",
    "lr_test_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear regression mean absolute error, train and test\n",
    "mean_absolute_error(y_train, lr_train_pred), mean_absolute_error(y_test, lr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_train, y_train)\n",
    "rf_train_pred = rf.predict(X_train)\n",
    "rf_test_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest regression mean absolute error, train and test.\n",
    "\n",
    "mean_absolute_error(y_train, rf_train_pred), mean_absolute_error(y_test, rf_test_pred)\n",
    "#Interestingly, a baseline Random Forest model overfits on the training data (unlike linear regression)\n",
    "#but doesn't perform much differently at all on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = pd.DataFrame(lr_test_pred)\n",
    "rf = pd.DataFrame(rf_test_pred)\n",
    "target = pd.DataFrame(y_test)\n",
    "target = target.reset_index().drop(columns = \"index\")\n",
    "df = pd.concat([lr, rf, target], axis = 1)\n",
    "df.columns = [\"Linear Regression\", \"Random Forest Regression\", \"Home_Score_Adv_Target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()\n",
    "\n",
    "#Ah. The means of the predictions (both models) tightly hug the mean of the target, but the standard deviations\n",
    "#are less than half that of the target. Duly, these regression models are playing it safe, trying to fit the best\n",
    "#line to the data. Regression isn't the right paradigm at all here, and classification is more practical anyway than\n",
    "#exact score difference prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Outcome Prediction: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)\n",
    "\n",
    "df = one_hot_encode(df)\n",
    "\n",
    "#Get our outcome category feature from the home score advantage feature, and then drop the home score advantage feature\n",
    "def home_away_draw(row):\n",
    "    if row[\"Home_Score_Adv\"] > 0:\n",
    "        return \"H\"\n",
    "    elif row[\"Home_Score_Adv\"] < 0:\n",
    "        return \"A\"\n",
    "    else:\n",
    "        return \"D\"\n",
    "\n",
    "df[\"Outcome\"] = df.apply(home_away_draw, axis = 1)\n",
    "df = df.drop(columns = \"Home_Score_Adv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns = \"Outcome\"), df.Outcome.map(dict(zip([\"D\", \"H\", \"A\"], [0, 1, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I balance the class weights and set scoring to f1 to promote recall on draws (minority class) while\n",
    "#maintaining overall precision and avoiding sloppy over-guessing.\n",
    "\n",
    "#By default, the model almost completely neglects to recognize draws for the sake of slight advantages\n",
    "#in overall accuracy--not what we want.\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "f1 = make_scorer(f1_score, average = \"weighted\") #ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].\n",
    "param_grid = {\"max_depth\": [3, 4, 5, 6], \"learning_rate\": [0.01, 0.02, 0.03, 0.05], \"gamma\": [1, 2, 4, 5]} #Limiting the ceiling on these params to control overfitting.\n",
    "grid = GridSearchCV(estimator = xgb, param_grid = param_grid, n_jobs = -1, scoring = f1)\n",
    "class_weights = class_weight.compute_sample_weight(class_weight = \"balanced\", y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train, sample_weight = class_weights)\n",
    "xgb_train_pred = grid.predict(X_train)\n",
    "xgb_test_pred = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_df = pd.DataFrame(xgb_test_pred)\n",
    "target = pd.DataFrame(y_test)\n",
    "target_df = target.reset_index().drop(columns = \"index\") #Resetting the index is needed for concatenation\n",
    "df = pd.concat([xgb_df, target_df], axis = 1)\n",
    "df.columns = [\"XGBoost\", \"Target_Outcome\"]\n",
    "df[\"XGBoost\"] = df[\"XGBoost\"].map({0: \"D\", 1: \"H\", 2: \"A\"})\n",
    "df[\"Target_Outcome\"] = df[\"Target_Outcome\"].map({0: \"D\", 1: \"H\", 2: \"A\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_report, test_report = classification_report(y_train, xgb_train_pred), classification_report(y_test, xgb_test_pred)\n",
    "print(\"Train\\n\", train_report)\n",
    "print(\"Test\\n\", test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)\n",
    "df[\"Outcome\"] = df.apply(home_away_draw, axis = 1)\n",
    "print(\"Class percentage breakdown\")\n",
    "df[\"Outcome\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The overall test accuracy is 47%, which significantly outperforms a 33% random guess accuracy and slightly outperforms\n",
    "#the 45.7% home win rate. This ceiling on accuracy reflects the limits of static data, the unpredictability of the sport,\n",
    "#and the goal of balancing accuracy with overall classification performance. Hiking up the accuracy score without sacrificing\n",
    "#overall performance would take some smart feature engineering requiring time, effort, and a greater knowledge of the sport, plus\n",
    "#more rigorous and comprehensive hyperparameter tuning. For now, this project--focused more on the data engineering feats\n",
    "#than the final numbers--is a home win."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
